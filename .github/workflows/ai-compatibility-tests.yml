name: AI Compatibility Tests

# When to run: manually, on schedule, or when rules change
on:
  # Manual trigger
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: true
        default: 'critical'
        type: choice
        options:
          - critical
          - all
      models_to_test:
        description: 'Which models to test (comma-separated: gpt4,claude,gemini,codestral)'
        required: true
        default: 'gpt4'
        type: string
  
  # Weekly schedule (Sundays at 00:00 UTC) - cost-effective
  schedule:
    - cron: '0 0 * * 0'
  
  # When rules or processes change
  push:
    paths:
      - '.ai-iap/rules/**'
      - '.ai-iap/processes/**'
    branches:
      - main

# Cost control: Only run one workflow at a time
concurrency:
  group: ai-tests
  cancel-in-progress: true

jobs:
  # ============================================================
  # Job 1: Test with GPT-4
  # ============================================================
  test-gpt4:
    name: Test GPT-4 Turbo
    runs-on: ubuntu-latest
    # Only run if GPT-4 is requested or scheduled AND API key exists
    if: |
      (github.event_name == 'schedule' || 
       (github.event_name == 'workflow_dispatch' && contains(github.event.inputs.models_to_test, 'gpt4'))) &&
      secrets.OPENAI_API_KEY != ''
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: .github/scripts/package.json
      
      - name: Install dependencies
        run: |
          cd .github/scripts
          npm ci
      
      - name: Run GPT-4 tests
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          cd .github/scripts
          node test-ai.js \
            --provider openai \
            --model gpt-4-turbo-preview \
            --test-suite ${{ github.event.inputs.test_suite || 'critical' }}
      
      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: gpt4-results
          path: .github/scripts/test-results/
          retention-days: 30

  # ============================================================
  # Job 2: Test with Claude
  # ============================================================
  test-claude:
    name: Test Claude 3.5 Sonnet
    runs-on: ubuntu-latest
    # Only run if Claude is requested or scheduled AND API key exists
    if: |
      (github.event_name == 'schedule' || 
       (github.event_name == 'workflow_dispatch' && contains(github.event.inputs.models_to_test, 'claude'))) &&
      secrets.ANTHROPIC_API_KEY != ''
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: .github/scripts/package.json
      
      - name: Install dependencies
        run: |
          cd .github/scripts
          npm ci
      
      - name: Run Claude tests
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          cd .github/scripts
          node test-ai.js \
            --provider anthropic \
            --model claude-3-5-sonnet-20241022 \
            --test-suite ${{ github.event.inputs.test_suite || 'critical' }}
      
      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: claude-results
          path: .github/scripts/test-results/
          retention-days: 30

  # ============================================================
  # Job 3: Test with Gemini
  # ============================================================
  test-gemini:
    name: Test Gemini 1.5 Pro
    runs-on: ubuntu-latest
    # Only run if Gemini is requested or scheduled AND API key exists
    if: |
      (github.event_name == 'schedule' || 
       (github.event_name == 'workflow_dispatch' && contains(github.event.inputs.models_to_test, 'gemini'))) &&
      secrets.GOOGLE_API_KEY != ''
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: .github/scripts/package.json
      
      - name: Install dependencies
        run: |
          cd .github/scripts
          npm ci
      
      - name: Run Gemini tests
        env:
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        run: |
          cd .github/scripts
          node test-ai.js \
            --provider google \
            --model gemini-1.5-pro \
            --test-suite ${{ github.event.inputs.test_suite || 'critical' }}
      
      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: gemini-results
          path: .github/scripts/test-results/
          retention-days: 30

  # ============================================================
  # Job 4: Test with Codestral
  # ============================================================
  test-codestral:
    name: Test Codestral
    runs-on: ubuntu-latest
    # Only run if Codestral is requested or scheduled AND API key exists
    if: |
      (github.event_name == 'schedule' || 
       (github.event_name == 'workflow_dispatch' && contains(github.event.inputs.models_to_test, 'codestral'))) &&
      secrets.MISTRAL_API_KEY != ''
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: .github/scripts/package.json
      
      - name: Install dependencies
        run: |
          cd .github/scripts
          npm ci
      
      - name: Run Codestral tests
        env:
          MISTRAL_API_KEY: ${{ secrets.MISTRAL_API_KEY }}
        run: |
          cd .github/scripts
          node test-ai.js \
            --provider mistral \
            --model codestral-latest \
            --test-suite ${{ github.event.inputs.test_suite || 'critical' }}
      
      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: codestral-results
          path: .github/scripts/test-results/
          retention-days: 30

  # ============================================================
  # Job 5: Analyze Results
  # ============================================================
  analyze-results:
    name: Analyze & Compare Results
    runs-on: ubuntu-latest
    needs: [test-gpt4, test-claude, test-gemini, test-codestral]
    # Run if at least one test job ran (not all skipped)
    if: |
      always() &&
      (needs.test-gpt4.result != 'skipped' ||
       needs.test-claude.result != 'skipped' ||
       needs.test-gemini.result != 'skipped' ||
       needs.test-codestral.result != 'skipped')
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download all results
        uses: actions/download-artifact@v4
        with:
          path: all-results
      
      - name: Analyze cross-AI consistency
        run: |
          cd .github/scripts
          node analyze-results.js ../all-results
      
      - name: Upload analysis
        uses: actions/upload-artifact@v4
        with:
          name: analysis-report
          path: .github/scripts/analysis-report.md
          retention-days: 90

  # ============================================================
  # Job 6: Report Status
  # ============================================================
  report-status:
    name: Report Status
    runs-on: ubuntu-latest
    needs: [analyze-results]
    if: always()
    
    steps:
      - name: Download analysis
        uses: actions/download-artifact@v4
        with:
          name: analysis-report
      
      - name: Post to GitHub Summary
        run: |
          cat analysis-report.md >> $GITHUB_STEP_SUMMARY
      
      - name: Comment on PR (if applicable)
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('analysis-report.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });

# Cost estimates:
# - Critical suite (3 tests): ~$0.20 per run
# - All tests (5 tests): ~$0.35 per run
# - Weekly schedule: ~$1.60/month (critical) or ~$2.80/month (all)
# - Per-commit (if enabled): Variable, depends on commit frequency

