name: AI Compatibility Tests

on:
  push:
    branches: [main, develop]
    paths:
      - '.ai-iap/rules/**'
      - '.ai-iap/config.json'
  pull_request:
    branches: [main, develop]
    paths:
      - '.ai-iap/rules/**'
      - '.ai-iap/config.json'
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Which test suite to run'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - critical
          - spring-boot
          - react
          - aspnet
          - fastapi
          - nextjs

env:
  # AI Model API Keys (stored as GitHub Secrets)
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
  GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
  MISTRAL_API_KEY: ${{ secrets.MISTRAL_API_KEY }}
  
  # Test configuration
  NODE_VERSION: '20'
  PYTHON_VERSION: '3.11'

jobs:
  validate-rules:
    name: Validate Rule Files
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Validate JSON files
        run: |
          echo "Validating config.json..."
          jq empty .ai-iap/config.json
          
          echo "Validating config.schema.json..."
          jq empty .ai-iap/config.schema.json

      - name: Check markdown files
        run: |
          echo "Checking for broken markdown in rules..."
          find .ai-iap/rules -name "*.md" -type f | while read file; do
            echo "Checking $file"
            # Basic markdown validation
            if ! grep -q "^#" "$file"; then
              echo "ERROR: $file has no headings"
              exit 1
            fi
          done

      - name: Verify CRITICAL REQUIREMENTS exist
        run: |
          echo "Checking critical framework files for CRITICAL REQUIREMENTS..."
          critical_files=(
            ".ai-iap/rules/typescript/frameworks/react.md"
            ".ai-iap/rules/java/frameworks/spring-boot.md"
            ".ai-iap/rules/dotnet/frameworks/aspnetcore.md"
            ".ai-iap/rules/python/frameworks/fastapi.md"
            ".ai-iap/rules/typescript/frameworks/nextjs.md"
          )
          
          for file in "${critical_files[@]}"; do
            if [ -f "$file" ]; then
              if ! grep -q "CRITICAL REQUIREMENTS" "$file"; then
                echo "ERROR: $file missing CRITICAL REQUIREMENTS section"
                exit 1
              fi
              echo "âœ“ $file has CRITICAL REQUIREMENTS"
            fi
          done

  test-gpt4:
    name: Test GPT-4
    runs-on: ubuntu-latest
    needs: validate-rules
    if: ${{ secrets.OPENAI_API_KEY != '' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install dependencies
        run: |
          cd .github/scripts
          npm install openai @anthropic-ai/sdk @google/generative-ai

      - name: Run GPT-4 tests
        id: test
        run: |
          node .github/scripts/test-ai.js \
            --model gpt-4-turbo-preview \
            --provider openai \
            --test-suite ${{ github.event.inputs.test_suite || 'critical' }}
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: gpt4-test-results
          path: test-results/gpt4-*.json

  test-claude:
    name: Test Claude 3.5 Sonnet
    runs-on: ubuntu-latest
    needs: validate-rules
    if: ${{ secrets.ANTHROPIC_API_KEY != '' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install dependencies
        run: |
          cd .github/scripts
          npm install openai @anthropic-ai/sdk @google/generative-ai

      - name: Run Claude tests
        id: test
        run: |
          node .github/scripts/test-ai.js \
            --model claude-3-5-sonnet-20241022 \
            --provider anthropic \
            --test-suite ${{ github.event.inputs.test_suite || 'critical' }}
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: claude-test-results
          path: test-results/claude-*.json

  test-gemini:
    name: Test Gemini Pro
    runs-on: ubuntu-latest
    needs: validate-rules
    if: ${{ secrets.GOOGLE_API_KEY != '' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install dependencies
        run: |
          cd .github/scripts
          npm install openai @anthropic-ai/sdk @google/generative-ai

      - name: Run Gemini tests
        id: test
        run: |
          node .github/scripts/test-ai.js \
            --model gemini-1.5-pro \
            --provider google \
            --test-suite ${{ github.event.inputs.test_suite || 'critical' }}
        env:
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: gemini-test-results
          path: test-results/gemini-*.json

  test-codestral:
    name: Test Codestral
    runs-on: ubuntu-latest
    needs: validate-rules
    if: ${{ secrets.MISTRAL_API_KEY != '' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install dependencies
        run: |
          cd .github/scripts
          npm install openai @anthropic-ai/sdk @google/generative-ai

      - name: Run Codestral tests
        id: test
        run: |
          node .github/scripts/test-ai.js \
            --model codestral-latest \
            --provider mistral \
            --test-suite ${{ github.event.inputs.test_suite || 'critical' }}
        env:
          MISTRAL_API_KEY: ${{ secrets.MISTRAL_API_KEY }}

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: codestral-test-results
          path: test-results/codestral-*.json

  analyze-results:
    name: Analyze Test Results
    runs-on: ubuntu-latest
    needs: [test-gpt4, test-claude, test-gemini, test-codestral]
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          path: test-results/

      - name: Analyze results
        run: |
          python .github/scripts/analyze-results.py \
            --results-dir test-results/ \
            --output test-results/summary.md

      - name: Generate comparison report
        run: |
          python .github/scripts/generate-report.py \
            --results-dir test-results/ \
            --output test-results/comparison.md

      - name: Upload summary
        uses: actions/upload-artifact@v4
        with:
          name: test-summary
          path: test-results/*.md

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('test-results/summary.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });

      - name: Check for failures
        run: |
          python .github/scripts/check-thresholds.py \
            --results-dir test-results/ \
            --min-score 90

  report-status:
    name: Report Overall Status
    runs-on: ubuntu-latest
    needs: analyze-results
    if: always()
    steps:
      - name: Download summary
        uses: actions/download-artifact@v4
        with:
          name: test-summary
          path: test-results/

      - name: Create job summary
        run: |
          cat test-results/summary.md >> $GITHUB_STEP_SUMMARY

      - name: Post to Slack
        if: ${{ secrets.SLACK_WEBHOOK_URL != '' && (github.event_name == 'push' || github.event_name == 'schedule') }}
        run: |
          curl -X POST ${{ secrets.SLACK_WEBHOOK_URL }} \
            -H 'Content-Type: application/json' \
            -d "{\"text\": \"AI Compatibility Tests completed. Check workflow for details.\"}"


